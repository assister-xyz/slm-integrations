{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b8f1b91-1599-45b9-ae4d-f48a772fe8e3",
   "metadata": {},
   "source": [
    "## SOLANA onchain bot\n",
    "## Plain agentic usage of Assisterr SLM models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f69a5995-546c-4ac1-b560-26b6b8930058",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install partial_json_parser\n",
    "!pip install termcolor\n",
    "!pip install json-repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "355a9ed3-4f17-40bb-970c-8e2a3008954d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from partial_json_parser import loads\n",
    "from json_repair import repair_json\n",
    "from termcolor import colored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c4a259b-2c7d-4f9d-a451-0f358c9ab8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Key can be obtained from https://build.assisterr.ai/ailab \n",
    "ASSISTERR_API_KEY = ''\n",
    "ASSISTERR_BASE_URL = 'https://api.assisterr.ai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "067bd7fb-e7f0-490f-8c85-9554d6381c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic ASSISTERR SLM class to make calls and construct prompt with history context\n",
    "\n",
    "class ASSISTERR_SLM:\n",
    "    def __init__(self, model_slug):\n",
    "        self.model = model_slug\n",
    "\n",
    "    def construct_prompt(self, question, chat_history):\n",
    "        \"\"\"Create prompt\n",
    "        Args:\n",
    "            question: str; query from user\n",
    "            chat_history: list; list of formatted conversation history\n",
    "        Returns:\n",
    "            Prompt text to be used in the model\n",
    "        \"\"\"\n",
    "\n",
    "        chat_history_formatted = self.format_chat_history(chat_history)\n",
    "        msg = f\"<|start_header_id|>user<|end_header_id|>\\n{question}<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "        final_prompt = chat_history_formatted + msg\n",
    "        return final_prompt\n",
    "\n",
    "    def format_chat_history(self, chat_history):\n",
    "        \"\"\"Format chat history\n",
    "        Args:\n",
    "            chat_history: list; list of conversation history\n",
    "        Returns:\n",
    "            Formatted chat history string\n",
    "        \"\"\"\n",
    "        formatted_history = \"\"\n",
    "        for entry in chat_history:\n",
    "            user_input = entry['user']\n",
    "            assistant_response = entry['assistant']\n",
    "            formatted_history += f\"<|start_header_id|>user<|end_header_id|>\\n{user_input}<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n{assistant_response}<|eot_id|>\\n\"\n",
    "        return formatted_history\n",
    "\n",
    "    def get_response(self, question):\n",
    "        \"\"\"Generate response using\n",
    "        Args:\n",
    "            question: str; question from the user\n",
    "        Returns:\n",
    "            The generated AI response text\n",
    "        \"\"\"\n",
    "\n",
    "        prompt = self.construct_prompt(question, chat_history_simulation)\n",
    "\n",
    "        request = json.dumps(prompt)\n",
    "\n",
    "                \n",
    "        url = f'{ASSISTERR_BASE_URL}/api/v1/slm/{self.model}/chat/'\n",
    "    \n",
    "        response = requests.post(url=url, headers={'X-Api-Key': ASSISTERR_API_KEY}, json={'query': request})\n",
    "        result = response.json()['message']\n",
    "        \n",
    "        chat_history_simulation.append({'user': question, 'assistant': result})\n",
    "        return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9e12f8e-0e4a-4a9e-acc8-cbcdf6f4b85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLANA API action calling based on Assisterr SLM chosen endpoint and provided payload to make call with\n",
    "\n",
    "def make_call(payload):\n",
    "    url = \"https://api.mainnet-beta.solana.com\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    payload.update({\"jsonrpc\": \"2.0\", \"id\": 1})\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5195aecc-4537-4edb-8fec-179f14674cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " what is the balance of benRLpbWCL8P8t51ufYt522419hGF5zif3CqgWGbEUm wallet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mI'm a Solana chain API bot. You can execute any onchain operations for users based on their requests.\u001b[0m\n",
      "\u001b[31mThe balance of the benRLpbWCL8P8t51ufYt522419hGF5zif3CqgWGbEUm wallet is 1941.503393146 SOL.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m agent \u001b[38;5;241m=\u001b[39m ASSISTERR_SLM(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolana_api_bot\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 9\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     api_call \u001b[38;5;241m=\u001b[39m loads(repair_json(agent\u001b[38;5;241m.\u001b[39mget_response(query)))\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(colored(api_call[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponding_message\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/PycharmProjects/ai-insights/src/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/ai-insights/src/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Some chat history simulation to control agent context\n",
    "chat_history_simulation = [\n",
    "    {\"user\": \"\",\n",
    "     \"assistant\": \"Hey I'm here to help! what are you interested in?\"},\n",
    "]\n",
    "\n",
    "# Initializae slm with already created model solana_api_bot\n",
    "agent = ASSISTERR_SLM('solana_api_bot')\n",
    "\n",
    "\n",
    "# some chat simulation to perform onchain operations\n",
    "# 1. Grab user input\n",
    "# 2. Call SLM\n",
    "# 3. Automatically call SOLANA API based on SLM response\n",
    "\n",
    "while True:\n",
    "    query = input()\n",
    "    api_call = loads(repair_json(agent.get_response(query)))\n",
    "    print(colored(api_call['responding_message'], 'red'))\n",
    "    call_payload = api_call['payload']\n",
    "    while call_payload:\n",
    "        result = make_call(api_call['payload'])\n",
    "        response = loads(repair_json(agent.get_response({'payload': result})))\n",
    "        print(colored(response['responding_message'], 'red'))\n",
    "\n",
    "        if response['payload']:\n",
    "            print(response['payload'])\n",
    "            call_payload = response['payload']\n",
    "        else:\n",
    "            call_payload = None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff978e68-a7ac-4ac0-8f32-69171f9d7c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed85eb3-7148-4542-a93d-5ab24d575c68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
